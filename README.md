# 5.20任务：

1. 看下最近7天浏览器push下文章title(和url)的曝光数，从大到小排序
2. 看下用户画像有哪些字段
3. 站内push，其中表中docid等于xmpush中的itemid等于snapshot中的id

粗粒度的可以按人群进行push；细粒度的话可以类似个性化push，这个还要想
活跃度，


# 5.21任务

站内push 1. 内容池 2. 线上服务；这些别人会做，我们需要想办法召回

1. app端模型，用户首刷
2. 运营会出一些好的资讯
3. 专门的用户人群
4. 目前线上服务能用的模型就是FM



今天的任务一：

i 看下哪些人群点击率比较高

ii 看下feed流和非feed流的点击率情况

# 5.22任务


export PYSPARK_DRIVER_PYTHON="ipython"

export PYSPARK_DRIVER_PYTHON_OPTS="notebook"

alias snotebook='$SPARK_PATH/bin/pyspark --masterlocal[2]'

# 5.23任务

# 5.24任务

# 5.27任务

# 5.28任务

跑出浏览器画像表和o2o_noenter表，通过deviceid进行join根据点击率看下用户画像特征

# 5.29任务
解析浏览器画像表feeds_behavior字段
# 5.30任务
# 6.3任务

# 8.22任务

# 8.23任务 deepdive安装完成，跑一下数据测试

# 8.27任务 deepdive测试，跑模型
# 8.29任务 debug和deepdive继续测试

# 9.3跑deepdive框架，跑关系抽取
# 9.4 跑通bxzr实体识别和关系抽取, 跑完NER
# 9.5 跑完RE看下效果
# 9.6 生成测试集和训练集，测试集是全量的candidate

# 9.9 跑版式识别框架，table这块
# 9.15完成ppt
# 9.16 已经完成ppt，完成保险条款抽取
# 9.17 汇报
# 9.18任务 neo4j
# 9.19任务 完成neo4j构建 java
# 9.19任务 探索neo4j构建 python
# 9.20任务 python neo4j建整个规划图谱
# 9.21任务 打比赛
# 9.22跑中文分类模型
# 9.23跑一下比赛分类，只用bert词向量
# 提交分数
# 用bert跑一下比赛
# 衍生一些统计特征
# 看下模型融合的效果(tfidf+lr, textCNN)
# 跑一下fastnlp ner模型用bert-base-cased模型
# 跑关系抽取
# 完成本月任务
# 完成版式识别优化
# 完成版式识别算法优化
# 非目录结构识别
# 二分类算法
# 用词向量看下效果
# 优化保险责任表格
# 明天提交sub19
# 跑一下textcnn for content
# 更新下版式识别算法，针对无目录
# 重新跑一下KG knowledge
# 版式识别手工改动
# 看下python从入门到精通。。
# 文件识别导入mongodb
# 看下quora pair明天bert能跑完，提交
# 看下quora insincere明天bert跑完，提交
# 看下ZEN模型怎么跑，下载中
# 提交结果到kaggle
# 看下word2vec论文
# 梳理下同义词词库
# 看下zen并跑通
# 抽取宏信息
# 抽取宏信息-二维码
# 宏信息提取完成
# KBQA信息抽取
# 

















